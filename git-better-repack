#! /usr/bin/python

# Copyright 2017 by Vincent Fourmond
# This program is free software. It is distributed under the terms of the
# GNU General Public License version 3.0 or later, found at
# https://www.gnu.org/copyleft/gpl.html
#
# There is NO WARRANTY.

# I'm unsure what this does as of now, but it's going to be fun !

import os
import re
import os.path
import glob

import argparse
import random
import shutil
import subprocess

# For categorizing files.
import magic

parser = argparse.ArgumentParser()
parser.add_argument("action", default=['dump-objects'], nargs='*',
                    help="action to be performed")
parser.add_argument("-s", "--size", type=int,
                    help="size (MB)")
parser.add_argument("--mess-up", type=int,
                    help="create a fake repository based on the files in the current directory with several operations")
parser.add_argument("-n", "--dry-run",action="store_true",
                    help="dry run (don't repack)")
parser.add_argument("-r", "--repack-size", type=int,
                    help="size of loose objects necessary to run git-repack (MB)")
args = parser.parse_args()

# Provide default values
if args.size:                   # in bytes !
    args.size *= 1024**2
else:
    args.size = 10*1024**2

if args.repack_size:            
    args.repack_size *= 1024 # in KB, compared to count_objects
else:
    args.repack_size = 10*1024



class git_rep:
    """A whole git repository"""

    def __init__(self):
        """Creates a repository object referring to the current directory"""
        if os.path.isdir(".git/objects"):
            self.obj_dir = ".git/objects"
        elif os.path.isdir("objects"):
            self.obj_dir = "objects" # bare repository
        else:
            raise RuntimeError("Must be at the root of a git repository")

    def list_packs(self):
        """Finds all pack files, and record them. Does not read them, though,
as it can be soo long !"""
        self.packs = []
        for pck in glob.glob(self.obj_dir + "/pack/*.pack"):
            self.packs.append(packfile(pck, self))
        return self.packs


    def count_objects(self):
        rv = dict()
        with os.popen('git count-objects -v') as gco:
            for line in gco:
                lst = line.split(":")
                rv[lst[0]] = int(lst[1])
        self.count_objects = rv
        return self.count_objects

    def cheap_gc(self):
        """Runs git repack to pack loose objects and cleanup packs. A weak but
cheap version of git gc"""
        os.system("git repack -d")

    def drop_redundant_packs(self):
        with os.popen('git pack-redundant --all') as gpr:
            for line in gpr:
                pck = line.rstrip()
                print "Removing redundant pack: %s" % pck
                os.unlink(pck)

    def simple_repack(self, size_threshold, tolerance = 1.5,
                      dry_run = False):
        """Given a threshold of pack size, consolidate all packs significantly
smaller than the threshold into single packs whose size shouldn't
exceed tolerance times the threshold."""
        self.cheap_gc()
        self.drop_redundant_packs()
        packs = []
        ts = 0
        rt = size_threshold * tolerance * 0.5
        for pack in rep.list_packs():
            print pack
            if pack.size < rt:
                pack.read_pack()
                packs.append(pack)
                ts += pack.size
                if ts > rt:
                    packfile.repack(packs, dry_run)
                    packs = []
                    ts = 0
                    print pack
            else:
                print "Pack %s too big, not touching it" % pack
        if len(packs) > 1:
            packfile.repack(packs, dry_run)
        self.drop_redundant_packs()

    def repack_v2(self, size_threshold, tolerance = 1.5, dry_run = False):
        """Attemps to be more clever than simple_repack by maximizing the chances of deltas"""
        self.cheap_gc()
        self.drop_redundant_packs()
        packs = []
        ts = 0
        rt = size_threshold * tolerance * 0.5
        for pack in rep.list_packs():
            if pack.size < rt:
                pack.read_pack()
        # Hmmm need to check the file types, but also try to avoid
        # generating too many packs...
        

    def cross_reference_objects(self):
        """Runs over all the packs, and records all the objects' SHA1 together
with the packs they are found in. Assumes the packs are already read. Returns the shas of duplicate objects"""
        self.all_objects = {}
        dups = []
        for pck in self.packs:
            for obj in pck.objects.values():
                if not obj.sha1 in self.all_objects:
                    self.all_objects[obj.sha1] = []
                else:
                    dups.append(obj.sha1)
                self.all_objects[obj.sha1].append(pck)
        return dups

    def dump_objects(self):
        st = {}
        for pck in self.list_packs():
            print "Reading pack %s" % pck.pack_file
            pck.read_pack()
            pck.read_object_sizes()
            sts = pck.stats()
            print " -> %s " % sts
            for n in sts.keys():
                st[n] = st.get(n, 0) + sts[n]
        dups = self.cross_reference_objects()
        print "%d duplicate objects" % len(dups)
        print st
        

class packed_object:
    def __init__(self, lst, pck):
        self.sha1 = lst[0]
        self.kind = lst[1]
        self.size = int(lst[2])
        self.packed_size = int(lst[3])
        self.file_size = None
        self.pack = pck
        self.base = None
        if len(lst) > 6:
            self.base_ref = lst[6]
        else:
            self.base_ref = False

    def root(self):
        """The root object"""
        if self.base is None:
            return self
        else:
            return self.base.root()

    def read_size(self):
        with os.popen('git cat-file -s %s' % self.sha1) as gcf:
            for line in gcf:
                self.file_size = int(line)
        return self.file_size


    def __str__(self):
        delta = ""
        if self.base:
            delta = " (delta)"
        
        return "object: %s, %s, size: %d/%d %s" % (self.sha1,
                                                   self.kind,
                                                   self.size,
                                                   self.packed_size,
                                                   delta)


class interconnected_objects:
    """A series of objects in a pack that are dependent on one another (in
terms of storage, i.e. objects that are deltas of a single root object"""

    def __init__(self, ele):
        self.root = ele.root()
        # Elements inside the 
        self.objects = {}
        self.add_object(ele)

    def is_sibling(self, obj):
        """Returns true if the object is a sibling (or already in) the pack"""
        return obj.root() == self.root

    def add_object(self, obj):
        if not self.is_sibling(obj):
            raise "Wrong object"

        while True:
            base = obj.base
            if base is None or base in self.objects:
                break
            self.objects[obj] = base
            obj = base

    def stats(self):
        st = {
            'objects': len(self.objects),
            'object_size': 0,
            'total_size': 0,
            'packed_size':0
        }
        for obj in self.objects.values():
            st['object_size'] += obj.size
            if obj.file_size is not None:
                st['total_size'] += obj.file_size
            st['packed_size'] += obj.packed_size
        return st
            
        

class packfile:
    def __init__(self, pck, rep):
        self.pack_file = pck
        self.size = os.path.getsize(pck)
        self.objects = {}
        self.interconnected_objects = {}
        self.lone_objects = set()
        self.rep = rep

    def __str__(self):
        return "packfile: %s, size: %d, %d objects" % (self.pack_file,
                                                       self.size,
                                                       len(self.objects))
    def read_pack(self):
        with os.popen('git verify-pack -v %s' % self.pack_file) as gvp:
            for line in gvp:
                lst = line.split()
                if len(lst[0]) == 40:
                    obj = packed_object(lst, self)
                    self.objects[obj.sha1] = obj
        # Now, we go over them again, cross-referencing them.
        for obj in self.objects.values():
            if obj.base_ref:
                obj.base = self.objects[obj.base_ref]
            else:
                obj.base = None

        # A pass to categorize the objects, has to come second for the
        # obj.base x-ref to be useable
        for obj in self.objects.values():
            if obj.base is None:
                self.lone_objects.add(obj)
            else:
                root = obj.root()
                if root in self.interconnected_objects:
                    self.interconnected_objects[root].add_object(obj)
                else:
                    self.interconnected_objects[root] = interconnected_objects(obj)
            

    def read_object_sizes(self):
        """Reads the sizes of all the objects"""
        proc = subprocess.Popen(['git','cat-file',
                                 '--batch-check=%(objectsize)'],
                                stdout=subprocess.PIPE,
                                stderr=subprocess.STDOUT,
                                stdin=subprocess.PIPE)
        objs = self.objects.values();
        inp = "\n".join(map(lambda x: x.sha1, objs))
        out, err = proc.communicate(inp)
        i = 0
        for ln in out.split("\n"):
            if len(ln) < 1:
                break
            objs[i].file_size = int(ln)
            i+= 1
        
    def stats(self):
        st = {
            'objects': 0,
            'object_size': 0,
            'total_size': 0,
            'deltas': 0,
            'lone_objects': len(self.lone_objects),
            'interconnected_hierarchies': len(self.interconnected_objects),
            'packed_size':0
        }
        for obj in self.objects.values():
            st['objects'] += 1
            if obj.base is not None:
                st['deltas'] += 1
            st['object_size'] += obj.size
            if obj.file_size is not None:
                st['total_size'] += obj.file_size
            st['packed_size'] += obj.packed_size
        return st

    @staticmethod
    def repack(packs, dry_run=False):
        """Repacks the given packs"""
        if dry_run:
            print "Would repack packs: %s" % (", ".join(map(lambda x: x.pack_file, packs)))
                
        else:
            print "Repacking packs: %s" % (", ".join(map(lambda x: x.pack_file, packs)))
            with os.popen('git pack-objects .git/objects/pack/pack --threads=1', 'w') as gpa:
                for pck in packs:
                    for o in pck.objects.values():
                        gpa.write("%s\n" % o.sha1)



                        
def mess_up(mu):
    """Creates a git repository in a subdirectory, and add files and modify them randomly"""
    orig_files = map(lambda x: "../%s" % x, glob.glob('*'))
    print orig_files
    if not os.path.isdir(".git/objects"):
        os.mkdir("tst-git")
    os.chdir("tst-git")
    if not os.path.isdir(".git"):
        os.system("git init")

    
    cur_files = []

    def call(*args):
        # print "Running: '%s'" % ("', '".join(args))
        subprocess.call(args)

    nbt = len(orig_files)/2
    if nbt < 1:
        nbt = 1
    elif nbt >= 100:
        nbt = 99
    
    while mu > 0:
        mu -= 1
        action = random.randint(0,1)
        nn = "file_%02d" % (random.randint(0, nbt))
        if action == 0:         # copy from below
            of = random.choice(orig_files)
            shutil.copy(of, nn)
            call('git', 'add', nn)
            call('git', 'commit', '-m', "Imported %s to %s" % (of, nn))
            cur_files.append(nn)
        elif len(cur_files) > 0:
            if action == 1:
                # Add some bits of the file
                of = random.choice(cur_files)
                if of == nn:
                    mu += 1
                    continue
                nb = random.randint(10,20)
                with open(of, "rb") as src:
                    with open(nn, 'wb') as dst:
                        bts = src.read()
                        dst.write(bts)
                        dst.write(os.urandom(nb))
                call('git', 'add', nn)
                call('git', 'commit', '-m', "Copied %s to %s and added %d bytes" % (of, nn, nb))
        else:
            mu += 1
            continue
        repack = random.randint(0,2) < 1
        if repack or mu == 0:
            print "\n\n\nRepack"
            call('git', 'repack')
            print "-> done\n"
            

        
            

if args.mess_up:
    mess_up(args.mess_up)
    exit()

rep = git_rep()

actions = {
    'repack': lambda: rep.simple_repack(args.size, dry_run = args.dry_run),
    'dump-objects': rep.dump_objects
}


for action in args.action:
    code = actions.get(action, None)
    if code is not None:
        code()
    else:
        print "Unkown action: %s" % action



#     # Now, walk over all the pack files, gathers the one that are smaller
# # than a predefined pack size until their whole size is about the threshold

# co = rep.count_objects()
# if co["size"] > args.repack_size:
#     rep.repack()

# rep.drop_redundant_packs()
    
# packs = []
# ts = 0
# for pack in rep.list_packs():
#     if pack.size < args.size*0.8:
#         pack.read_pack()
#         packs.append(pack)
#         ts += pack.size
#         if ts > 0.8*args.size:
#             packfile.repack(packs, args.dry_run)
#             packs = []
#             ts = 0
#         print pack
#     else:
#         print "Pack %s too big, not touching it" % pack

# rep.drop_redundant_packs()
